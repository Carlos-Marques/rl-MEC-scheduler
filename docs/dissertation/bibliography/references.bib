@mastersthesis{Lulu,
  author  = {Luís Pires de Matos Morgado Ferreira},
  title   = {Fog Computing Task Offloading Optimization based on Deep Reinforcement Learning},
  school  = {Instituto Superior Técnico},
  year    = {2021},
}

@article{opengym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  archivePrefix = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{rllib,
    Author = {Eric Liang and
              Richard Liaw and
              Robert Nishihara and
              Philipp Moritz and
              Roy Fox and
              Ken Goldberg and
              Joseph E. Gonzalez and
              Michael I. Jordan and
              Ion Stoica},
    Title = {{RLlib}: Abstractions for Distributed Reinforcement Learning},
    Booktitle = {International Conference on Machine Learning ({ICML})},
    Year = {2018}
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@misc{kerasrl,
author = {Matthias Plappert},
title = {Deep Reinforcement Learning for Keras},
year = {2016},
publisher = {GitHub},
journal = {GitHub repository},
howpublished = {\url{https://github.com/keras-rl/keras-rl}},
note = {Online; Last access on 28/05/2021}
}

@misc{A3CImag,
author = {Chris Yoon},
title = {Understanding Actor Critic Methods and A2C},
year = {2019},
howpublished = {\url{https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f}},
note = {Online; Last access on 31/05/2021}
}

@misc{kerasrl2,
    author = {Taylor McNally},
    title = {Deep Reinforcement Learning for Tensorflow 2 Keras},
    year = {2019},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/wau/keras-rl2}},
    note = {Online; Last access on 31/05/2021}
}

@article{openaia2c,
  author    = {Yuhuai Wu and
               Elman Mansimov and
               Shun Liao and
               Roger B. Grosse and
               Jimmy Ba},
  title     = {Scalable trust-region method for deep reinforcement learning using
               Kronecker-factored approximation},
  journal   = {CoRR},
  volume    = {abs/1708.05144},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.05144},
  archivePrefix = {arXiv},
  eprint    = {1708.05144},
  timestamp = {Mon, 13 Aug 2018 16:48:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-05144.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{pythonpop,
author = {GitHub},
title = {The 2020 state of the octoverse},
year = {2020},
howpublished = {\url{https://octoverse.github.com/}},
note = {Online; Last access on 3/06/2021}
}

@misc{pythonmachine,
author = {GitHub},
title = {The State of the Octoverse: machine learning},
year = {2019},
howpublished = {\url{https://github.blog/2019-01-24-the-state-of-the-octoverse-machine-learning/}},
note = {Online; Last access on 3/06/2021}
}

@article{POMP,
title = {Planning and acting in partially observable stochastic domains},
journal = {Artificial Intelligence},
volume = {101},
number = {1},
pages = {99-134},
year = {1998},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(98)00023-X},
url = {https://www.sciencedirect.com/science/article/pii/S000437029800023X},
author = {Leslie Pack Kaelbling and Michael L. Littman and Anthony R. Cassandra},
keywords = {Planning, Uncertainty, Partially observable Markov decision processes},
abstract = {In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions.}
}

@book{RLbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@INPROCEEDINGS{energycons,  author={Wen, Yonggang and Zhang, Weiwen and Luo, Haiyun},  booktitle={2012 Proceedings IEEE INFOCOM},   title={Energy-optimal mobile application execution: Taming resource-poor mobile devices with cloud clones},   year={2012},  volume={},  number={},  pages={2716-2720},  doi={10.1109/INFCOM.2012.6195685}}

@misc{SESAM,
author = {H2020 European Project},
title = {Small cEllS coordinAtion for Multi-tenancy and edge services (SESAM)},
year = {2015},
howpublished = {\url{https://www.sesame-h2020-5g-ppp.eu/Home.aspx}},
note = {Online; Last access on 28/05/2021}
}

@misc{OpenFog,
author = {OpenFog Consortium},
title = {OpenFog Reference Architecture for Fog Computing},
year = {2017},
howpublished = {\url{https://iiconsortium.org/pdf/OpenFog_Reference_Architecture_2_09_17.pdf}},
note = {Online; Last access on 28/05/2021}
}

@article{MECspec,
  title={Mobile-edge computing introductory technical white paper},
  author={Patel, Milan and Naughton, Brian and Chan, Caroline and Sprecher, Nurit and Abeta, Sadayuki and Neal, Adrian and others},
  journal={White paper, mobile-edge computing (MEC) industry initiative},
  volume={29},
  pages={854--864},
  year={2014}
}

@inproceedings{mmcloud,
  title={Mobile micro-cloud: Application classification, mapping, and deployment},
  author={Wang, Shiqiang and Tu, Guan-Hua and Ganti, Raghu and He, Ting and Leung, Kin and Tripp, Howard and Warr, Katy and Zafer, Murtaza},
  booktitle={Proc. Annual Fall Meeting of ITA (AMITA)},
  year={2013}
}

@INPROCEEDINGS{fmcloud,
  author={Aissioui, Abdelkader and Ksentini, Adlen and Gueroui, Abdelhak},
  booktitle={2015 IEEE 11th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)}, 
  title={An efficient elastic distributed SDN controller for follow-me cloud}, 
  year={2015},
  volume={},
  number={},
  pages={876-881},
  doi={10.1109/WiMOB.2015.7348054}}

@ARTICLE{CONCERT,
  author={Liu, Jingchu and Zhao, Tao and Zhou, Sheng and Cheng, Yu and Niu, Zhisheng},
  journal={IEEE Wireless Communications}, 
  title={CONCERT: a cloud-based architecture for next-generation cellular systems}, 
  year={2014},
  volume={21},
  number={6},
  pages={14-22},
  doi={10.1109/MWC.2014.7000967}}

@inproceedings{
MobiScud,
author = {Wang, Kaiqiang and Shen, Minwei and Cho, Junguk and Banerjee, Arijit and Van der Merwe, Jacobus and Webb, Kirk},
title = {MobiScud: A Fast Moving Personal Cloud in the Mobile Network},
year = {2015},
isbn = {9781450335386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2785971.2785979},
doi = {10.1145/2785971.2785979},
abstract = {We present MobiScud, an evolutionary mobile network architecture that integrates cloud and SDN technologies into a standard mobile network in backwards compatible fashion. MobiScud enables personalized virtual machines to seamlessly "follow" mobile network users as they move around.},
booktitle = {Proceedings of the 5th Workshop on All Things Cellular: Operations, Applications and Challenges},
pages = {19–24},
numpages = {6},
keywords = {service offloading, mobile network, cloud computing, software define networking (SDN)},
location = {London, United Kingdom},
series = {AllThingsCellular '15}
}

@INPROCEEDINGS{smallcellcloud,  author={Lobillo, Felicia and Becvar, Zdenek and Puente, Miguel Angel and Mach, Pavel and Lo Presti, Francesco and Gambetti, Fabrizio and Goldhamer, Mariana and Vidal, Josep and Widiawan, Anggoro K. and Calvanesse, Emilio},  booktitle={2014 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)},   title={An architecture for mobile computation offloading on cloud-enabled LTE small cells},   year={2014},  volume={},  number={},  pages={1-6},  doi={10.1109/WCNCW.2014.6934851}}

@INPROCEEDINGS{adhoc,
  author={McGilvary, Gary A. and Barker, Adam and Atkinson, Malcolm},
  booktitle={2015 IEEE 8th International Conference on Cloud Computing}, 
  title={Ad Hoc Cloud Computing}, 
  year={2015},
  volume={},
  number={},
  pages={1063-1068},
  doi={10.1109/CLOUD.2015.153}}

@ARTICLE{cloudlet,  author={Satyanarayanan, Mahadev and Bahl, Paramvir and Caceres, Ramon and Davies, Nigel},  journal={IEEE Pervasive Computing},   title={The Case for VM-Based Cloudlets in Mobile Computing},   year={2009},  volume={8},  number={4},  pages={14-23},  doi={10.1109/MPRV.2009.82}}

@misc{dqnimage,
author = {Ankit Choudhar},
title = {A Hands-On Introduction to Deep Q-Learning using OpenAI Gym in Python},
year = {2019},
howpublished = {\url{https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/}},
note = {Online; Last access on 28/05/2021}
}

@article{DBLP:journals/corr/abs-1711-09012,
  author    = {Shermila Ranadheera and
               Setareh Maghsudi and
               Ekram Hossain},
  title     = {Mobile Edge Computation Offloading Using Game Theory and Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1711.09012},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.09012},
  archivePrefix = {arXiv},
  eprint    = {1711.09012},
  timestamp = {Mon, 13 Aug 2018 16:46:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-09012.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{fogmulti,
  author={Baek, Jungyeon and Kaddoum, Georges},
  journal={IEEE Internet of Things Journal}, 
  title={Heterogeneous Task Offloading and Resource Allocations via Deep Recurrent Reinforcement Learning in Partial Observable Multifog Networks}, 
  year={2021},
  volume={8},
  number={2},
  pages={1041-1056},
  doi={10.1109/JIOT.2020.3009540}}

@ARTICLE{7879258,
  author={Mach, Pavel and Becvar, Zdenek},
  journal={IEEE Communications Surveys   Tutorials}, 
  title={Mobile Edge Computing: A Survey on Architecture and Computation Offloading}, 
  year={2017},
  volume={19},
  number={3},
  pages={1628-1656},
  doi={10.1109/COMST.2017.2682318}}
  
@INPROCEEDINGS{taskclass2,
  author={Yu, Shuai and Wang, Xin and Langar, Rami},
  booktitle={2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)}, 
  title={Computation offloading for mobile edge computing: A deep learning approach}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/PIMRC.2017.8292514}}
  
@INPROCEEDINGS{NUE1mec,
  author={Li, Ji and Gao, Hui and Lv, Tiejun and Lu, Yueming},
  booktitle={2018 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Deep reinforcement learning based computation offloading and resource allocation for MEC}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/WCNC.2018.8377343}}
  
@ARTICLE{8444467,
  author={Dinh, Thinh Quang and La, Quang Duy and Quek, Tony Q. S. and Shin, Hyundong},
  journal={IEEE Transactions on Communications}, 
  title={Learning for Computation Offloading in Mobile Edge Computing}, 
  year={2018},
  volume={66},
  number={12},
  pages={6353-6367},
  doi={10.1109/TCOMM.2018.2866572}}
  
@ARTICLE{AGAcrypto,
  author={Qiu, Xiaoyu and Liu, Luobin and Chen, Wuhui and Hong, Zicong and Zheng, Zibin},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Online Deep Reinforcement Learning for Computation Offloading in Blockchain-Empowered Mobile Edge Computing}, 
  year={2019},
  volume={68},
  number={8},
  pages={8050-8062},
  doi={10.1109/TVT.2019.2924015}}
  
@INPROCEEDINGS{centralfog,
  author={Baek, Jung-yeon and Kaddoum, Georges and Garg, Sahil and Kaur, Kuljeet and Gravel, Vivianne},
  booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Managing Fog Networks using Reinforcement Learning Based Load Balancing Algorithm}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/WCNC.2019.8885745}}
  
@article{LIN2020102781,
title = {A survey on computation offloading modeling for edge computing},
journal = {Journal of Network and Computer Applications},
volume = {169},
pages = {102781},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102781},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302551},
author = {Hai Lin and Sherali Zeadally and Zhihong Chen and Houda Labiod and Lusheng Wang},
keywords = {Computation offloading, Edge computing, Modeling},
abstract = {As a promising technology, edge computing extends computation, communication, and storage facilities toward the edge of a network. This new computing paradigm opens up new challenges, among which computation offloading is considered to be the most important one. Computation offloading enables end devices to offload computation tasks to edge servers and receive the results after the servers' execution of the tasks. In computation offloading, offloading modeling plays a crucial role in determining the overall edge computing performance. We present a comprehensive overview on the past development as well as the recent advances in research areas related to offloading modeling in edge computing. First, we present some important edge computing architectures and classify the previous works on computation offloading into different categories. Second, we discuss some basic models such as channel model, computation and communication model, and energy harvesting model that have been proposed in offloading modeling. Next, we elaborate on different offloading modeling methods which are based on (non-)convex optimization, Markov decision process, game theory, Lyapunov optimization, or machine learning. Finally, we highlight and discuss some research directions and challenges in the area of offloading modeling in edge computing.}
}

@article{MIAO2020925,
title = {Intelligent task prediction and computation offloading based on mobile-edge cloud computing},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {925-931},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.035},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19320862},
author = {Yiming Miao and Gaoxiang Wu and Miao Li and Ahmed Ghoneim and Mabrook Al-Rakhami and M. Shamim Hossain},
keywords = {Artificial intelligence, Computation offloading, Edge computing, LSTM, Task migration},
abstract = {Edge computing overcomes the high communication delay shortcoming of traditional cloud computing and provides computing services with high reliability and high bandwidth for mobile devices. At present, edge computing has become the forefront and hotspot of mobile-edge cloud computing (MEC) research. However, with the increasing requirements and services of mobile users, offloading strategy of simple edge computing is no longer applicable to MEC architecture. This paper puts forward a new intelligent computation offloading based MEC architecture in combination with artificial intelligence (AI) technology. According to the data size of computation task from mobile users and the performance features of edge computing nodes, a computation offloading and task migration algorithm based on task prediction is proposed. The computation task prediction based on LSTM algorithm, computation offloading strategy for mobile device based on task prediction, and task migration for edge cloud scheduling scheme are used to assist in optimizing the edge computing offloading model. Experiments show that our proposed architecture and algorithm can effectively reduce the total task delay with the increasing data and subtasks.}
}

@article{SHAKARAMI2020107496,
title = {A survey on the computation offloading approaches in mobile edge computing: A machine learning-based perspective},
journal = {Computer Networks},
volume = {182},
pages = {107496},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107496},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311634},
author = {Ali Shakarami and Mostafa Ghobaei-Arani and Ali Shahidinejad},
keywords = {Computation offloading, Mobile edge computing, Machine learning, Reinforcement learning, Supervised learning, Unsupervised learning},
abstract = {With the rapid developments in emerging mobile technologies, utilizing resource-hungry mobile applications such as media processing, online Gaming, Augmented Reality (AR), and Virtual Reality (VR) play an essential role in both businesses and entertainments. To soften the burden of such complexities incurred by fast developments of such serving technologies, distributed Mobile Edge Computing (MEC) has been developed, aimed at bringing the computation environments near the end-users, usually in one hop, to reach predefined requirements. In the literature, offloading approaches are developed to connect the computation environments to mobile devices by transferring resource-hungry tasks to the near servers. Because of some rising problems such as inherent software and hardware heterogeneity, restrictions, dynamism, and stochastic behavior of the ecosystem, the computation offloading issues consider as the essential challenging problems in the MEC environment. However, to the best of the author's knowledge, in spite of its significance, in machine learning-based (ML-based) computation offloading mechanisms, there is not any systematic, comprehensive, and detailed survey in the MEC environment. In this paper, we provide a review on the ML-based computation offloading mechanisms in the MEC environment in the form of a classical taxonomy to identify the contemporary mechanisms on this crucial topic and to offer open issues as well. The proposed taxonomy is classified into three main fields: Reinforcement learning-based mechanisms, supervised learning-based mechanisms, and unsupervised learning-based mechanisms. Next, these classes are compared with each other based on the essential features such as performance metrics, case studies, utilized techniques, and evaluation tools, and their advantages and weaknesses are discussed, as well. Finally, open issues and uncovered or inadequately covered future research challenges are argued, and the survey is concluded.}
}

@Article{taskclass1,
author={Gong, Yongsheng
and Lv, Congmin
and Cao, Suzhi
and Yan, Lei
and Wang, Houpeng},
title={Deep learning-based computation offloading with energy and performance optimization},
journal={EURASIP Journal on Wireless Communications and Networking},
year={2020},
month={Mar},
day={30},
volume={2020},
number={1},
pages={69},
abstract={With the benefit of partially or entirely offloading computations to a nearby server, mobile edge computing gives user equipment (UE) more powerful capability to run computationally intensive applications. However, a critical challenge emerged: how to select the optimal set of components to offload considering the UE performance as well as its battery usage constraints. In this paper, we propose a novel energy and performance efficient deep learning based offloading algorithm. The optimal offloading schemes of components based on remaining energy and its performance can be determined by our proposed algorithm. All of these considerations are modeled as a cost function; then, a deep learning network is trained to compute the solution by which the optimal offloading scheme can be determined. Experimental results show that the proposed method is superior to existing methods in terms of energy and performance constraints.},
issn={1687-1499},
doi={10.1186/s13638-020-01678-5},
url={https://doi.org/10.1186/s13638-020-01678-5}
}

@article{discount,
  author    = {Vincent Fran{\c{c}}ois{-}Lavet and
               Rapha{\"{e}}l Fonteneau and
               Damien Ernst},
  title     = {How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies},
  journal   = {CoRR},
  volume    = {abs/1512.02011},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.02011},
  archivePrefix = {arXiv},
  eprint    = {1512.02011},
  timestamp = {Mon, 13 Aug 2018 16:46:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Francois-LavetF15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Mnih2015,
  doi = {10.1038/nature14236},
  url = {https://doi.org/10.1038/nature14236},
  year = {2015},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {518},
  number = {7540},
  pages = {529--533},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and Andreas K. Fidjeland and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  title = {Human-level control through deep reinforcement learning},
  journal = {Nature}
}

@Article{DQN,
author={Mnih, Volodymyr
and Kavukcuoglu, Koray
and Silver, David
and Rusu, Andrei A.
and Veness, Joel
and Bellemare, Marc G.
and Graves, Alex
and Riedmiller, Martin
and Fidjeland, Andreas K.
and Ostrovski, Georg
and Petersen, Stig
and Beattie, Charles
and Sadik, Amir
and Antonoglou, Ioannis
and King, Helen
and Kumaran, Dharshan
and Wierstra, Daan
and Legg, Shane
and Hassabis, Demis},
title={Human-level control through deep reinforcement learning},
journal={Nature},
year={2015},
month={Feb},
day={01},
volume={518},
number={7540},
pages={529-533},
abstract={An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
issn={1476-4687},
doi={10.1038/nature14236},
url={https://doi.org/10.1038/nature14236}
}

@inproceedings{doubleDQN,
author = {Hasselt, Hado van},
title = {Double Q-Learning},
year = {2010},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value. We introduce an alternative way to approximate the maximum expected value for any set of random variables. The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value. We apply the double estimator to Q-learning to construct Double Q-learning, a new off-policy reinforcement learning algorithm. We show the new algorithm converges to the optimal policy and that it performs well in some settings in which Q-learning performs poorly due to its overestimation.},
booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 2},
pages = {2613–2621},
numpages = {9},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'10}
}

@article{duelingDQN,
  author    = {Ziyu Wang and
               Nando de Freitas and
               Marc Lanctot},
  title     = {Dueling Network Architectures for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.06581},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06581},
  archivePrefix = {arXiv},
  eprint    = {1511.06581},
  timestamp = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WangFL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{prioexperience,
  title={Prioritized Experience Replay},
  author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
  journal={CoRR},
  year={2016},
  volume={abs/1511.05952}
}

@article{a3c,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  archivePrefix = {arXiv},
  eprint    = {1602.01783},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{a2c,
  author    = {Jane X. Wang and
               Zeb Kurth{-}Nelson and
               Dhruva Tirumala and
               Hubert Soyer and
               Joel Z. Leibo and
               R{\'{e}}mi Munos and
               Charles Blundell and
               Dharshan Kumaran and
               Matthew Botvinick},
  title     = {Learning to reinforcement learn},
  journal   = {CoRR},
  volume    = {abs/1611.05763},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.05763},
  archivePrefix = {arXiv},
  eprint    = {1611.05763},
  timestamp = {Mon, 13 Aug 2018 16:47:12 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WangKTSLMBKB16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{boltz,
  author    = {Nicol{\`{o}} Cesa{-}Bianchi and
               Claudio Gentile and
               G{\'{a}}bor Lugosi and
               Gergely Neu},
  title     = {Boltzmann Exploration Done Right},
  journal   = {CoRR},
  volume    = {abs/1705.10257},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.10257},
  archivePrefix = {arXiv},
  eprint    = {1705.10257},
  timestamp = {Mon, 13 Aug 2018 16:46:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Cesa-BianchiGLN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}